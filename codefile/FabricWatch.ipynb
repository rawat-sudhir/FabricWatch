{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyodbc pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abdc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Variables\n",
    "\n",
    "tenant_id = 'tenant-id'\n",
    "client_id = 'client_id'\n",
    "client_secret = 'client_secret'\n",
    "redirect_uri = 'http://localhost'  # This should match the redirect URI set in Azure AD\n",
    "scope = 'https://api.fabric.microsoft.com/Workspace.ReadWrite.All'\n",
    "authorization_url = f'https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/authorize'\n",
    "token_url = f'https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token'\n",
    "authentication = 'ActiveDirectoryServicePrincipal'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from urllib.parse import urlencode, urlparse, parse_qs\n",
    "\n",
    "# Azure AD and API endpoint details\n",
    "\n",
    "# Step 1: Get user authorization\n",
    "def get_authorization_code():\n",
    "    params = {\n",
    "        'client_id': client_id,\n",
    "        'response_type': 'code',\n",
    "        'redirect_uri': redirect_uri,\n",
    "        'response_mode': 'query',\n",
    "        'scope': scope\n",
    "    }\n",
    "    auth_request_url = f'{authorization_url}?{urlencode(params)}'\n",
    "    print(f'Please go to the following URL and authorize the application: {auth_request_url}')\n",
    "\n",
    "    redirect_response = input('Paste the full redirect URL here: ')\n",
    "    parsed_url = urlparse(redirect_response)\n",
    "    authorization_code = parse_qs(parsed_url.query)['code'][0]\n",
    "    return authorization_code\n",
    "\n",
    "# Step 2: Exchange authorization code for access token\n",
    "def get_tokens(authorization_code):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded'\n",
    "    }\n",
    "    body = {\n",
    "        'grant_type': 'authorization_code',\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "        'code': authorization_code,\n",
    "        'redirect_uri': redirect_uri,\n",
    "        'scope': scope\n",
    "    }\n",
    "    response = requests.post(token_url, headers=headers, data=body)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to call Fabric API for Lakehouses\n",
    "def call_lakehouse_api(workspace_id, access_token):\n",
    "    \n",
    "    api_url = f'https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/lakehouses'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to call Fabric API for Warehouses\n",
    "def call_warehouse_api(workspace_id, access_token):\n",
    "    api_url = f'https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/warehouses'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data, filename='output.csv'):\n",
    "    keys = data[0].keys()\n",
    "    with open(filename, 'w', newline='') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Get authorization code from user\n",
    "        authorization_code = get_authorization_code()\n",
    "        \n",
    "        # Exchange the authorization code for access and refresh tokens\n",
    "        token_response = get_tokens(authorization_code)\n",
    "        \n",
    "        # Extract the access token from the response\n",
    "        access_token = token_response['access_token']\n",
    "        \n",
    "        # List of workspace IDs (for example purposes)\n",
    "        workspace_ids = ['Workspaceid-1','Workspaceid-2','Workspaceid-3']\n",
    "        \n",
    "        all_data = []\n",
    "\n",
    "        for workspace_id in workspace_ids:\n",
    "            lakehouse_response = call_lakehouse_api(workspace_id, access_token)\n",
    "            warehouse_response = call_warehouse_api(workspace_id, access_token)\n",
    "            \n",
    "            for lakehouse in lakehouse_response['value']:\n",
    "                lakehouse_data = {\n",
    "                    'id': lakehouse['id'],\n",
    "                    'type': lakehouse['type'],\n",
    "                    'displayName': lakehouse['displayName'],\n",
    "                    'description': lakehouse['description'],\n",
    "                    'workspaceId': lakehouse['workspaceId'],\n",
    "                    'oneLakeTablesPath': lakehouse['properties']['oneLakeTablesPath'],\n",
    "                    'oneLakeFilesPath': lakehouse['properties']['oneLakeFilesPath'],\n",
    "                    'sqlEndpointConnectionString': lakehouse['properties']['sqlEndpointProperties']['connectionString'],\n",
    "                    'provisioningStatus': lakehouse['properties']['sqlEndpointProperties']['provisioningStatus']\n",
    "                }\n",
    "                all_data.append(lakehouse_data)\n",
    "            for warehouse in warehouse_response['value']:\n",
    "                warehouse_data = {\n",
    "                    'id': warehouse['id'],\n",
    "                    'type': warehouse['type'],\n",
    "                    'displayName': warehouse['displayName'],\n",
    "                    'description': warehouse['description'],\n",
    "                    'workspaceId': warehouse['workspaceId'],\n",
    "                    'oneLakeTablesPath':'NA',\n",
    "                    'oneLakeFilesPath': 'NA',\n",
    "                    'sqlEndpointConnectionString': warehouse['properties']['connectionInfo']\n",
    "                }\n",
    "                all_data.append(warehouse_data)\n",
    "        \n",
    "        # Save all collected data to a CSV file\n",
    "        save_to_csv(all_data)\n",
    "        print('All information is saved in a CSV File')\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f'HTTP error occurred: {err}')\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da10f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def read_connection_details(csv_file):\n",
    "    connections = []\n",
    "    with open(csv_file, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if row['type'] in ['Lakehouse', 'Warehouse']:\n",
    "                connection_string = row['sqlEndpointConnectionString']\n",
    "                connections.append({\n",
    "                    'connection_string': connection_string,\n",
    "                    'database_name': row['displayName']\n",
    "                })\n",
    "    return connections\n",
    "\n",
    "def execute_query_and_save_to_csv(connection_string, database_name, query, output_file):\n",
    "    try:\n",
    "        conn_str = (\n",
    "            f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
    "            f\"Server={connection_string};\"\n",
    "            f\"Database={database_name};\"\n",
    "            f\"Authentication={authentication};\"\n",
    "            f\"Uid={client_id};\"\n",
    "            f\"Pwd={client_secret};\"\n",
    "            f\"Authority Id={tenant_id};\"\n",
    "            f\"Encrypt=yes;\"\n",
    "            f\"TrustServerCertificate=no;\"\n",
    "            f\"Connection Timeout=30;\"\n",
    "        )\n",
    "        conn = pyodbc.connect(conn_str)\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f'Results saved to {output_file}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "def main():\n",
    "\n",
    "    csv_file = 'output.csv'\n",
    "    query = \"SELECT * FROM [queryinsights].[exec_requests_history]\"\n",
    "    \n",
    "    connections = read_connection_details(csv_file)\n",
    "\n",
    "    for i, conn_details in enumerate(connections):\n",
    "        \n",
    "        output_file = f'query_results_{i+1}.csv'\n",
    "        print(conn_details['connection_string'])\n",
    "        print(conn_details['database_name'])\n",
    "        print(output_file)\n",
    "        execute_query_and_save_to_csv(\n",
    "            conn_details['connection_string'],\n",
    "            conn_details['database_name'],\n",
    "            query,\n",
    "            output_file\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd784057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
